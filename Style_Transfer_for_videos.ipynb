{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrgN3QCW7JjwML75RcJVRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DulaniDeSilva/Deep_Learning_Neural_Networks/blob/main/Style_Transfer_for_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required Dependencies"
      ],
      "metadata": {
        "id": "9V6POKoV2kts"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6yndEVDAleP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model from TensorFlow Hub"
      ],
      "metadata": {
        "id": "AdAGcKcu2osn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')"
      ],
      "metadata": {
        "id": "G6qvu16o2chX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "images are given as input to the model, that images need to be preprocessed. image_read() function converts image to the tensor normalize it by dividing pixels to 255 and the resize it"
      ],
      "metadata": {
        "id": "D9OlNeYn2tbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_read(image):\n",
        "  max_dim=512\n",
        "  image= tf.convert_to_tensor(image, dtype = tf.float32)\n",
        "  image= image/255.0\n",
        "  shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim/long_dim\n",
        "  new_shape = tf.cast(shape*scale, tf.int32)\n",
        "  new_image = tf.image.resize(image, new_shape)\n",
        "  new_image = new_image[tf.newaxis, :]\n",
        "\n",
        "  return new_image"
      ],
      "metadata": {
        "id": "nGM-aM1r2jT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "new function tensor_toimage() created for converting output tensor of model to the numpy array. Helps to describe it as image format which can be used for the frames of new neural style transfered video\n"
      ],
      "metadata": {
        "id": "MrJtITbj3EU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_toimage(tensor):\n",
        "  tensor =tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0]==1\n",
        "    tensor=tensor[0]\n",
        "\n",
        "  return tensor"
      ],
      "metadata": {
        "id": "gbd-vCtj3UXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading image and video"
      ],
      "metadata": {
        "id": "p4WA_vTJ3b-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "style_im = cv2.imread(\"/content/style.jpg\")\n",
        "style_im = cv2.cvtColor(style_im, cv2.COLOR_BGR2RGB)\n",
        "style_im = image_read(style_im)\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/content.mp4\")"
      ],
      "metadata": {
        "id": "57n5lUS43bbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret, frame = cap.read()\n",
        "frame_width = image_read(frame)[0].shape[1]\n",
        "frame_height= image_read(frame)[0].shape[0]\n",
        "\n",
        "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'XVID'), 10,\n",
        "                      (frame_width,frame_height))\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = image_read(frame)\n",
        "    stylized_frame = hub_model(tf.constant(frame), tf.constant(style_im))[0]\n",
        "    image = tensor_toimage(stylized_frame)\n",
        "    out.write(image)\n",
        "  else:\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "id": "hiR2utdt4RMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}